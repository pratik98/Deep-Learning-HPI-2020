{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "week5_804861.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SCfIunp_Q6y2",
        "IIes1em49fNw",
        "FPxGr6ek9fN4",
        "Kja7I86v9fN9",
        "nKaBc4WJ9fOA",
        "KTyiIuGa9fOC"
      ]
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d234f47b1b2941b8bc0fd941df65d4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99b9eea7cf54427d9b197660a430f68d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed0497a420364e01b215df934139c6d9",
              "IPY_MODEL_973a4c38bae64eb49be08ebb803f102f"
            ]
          }
        },
        "99b9eea7cf54427d9b197660a430f68d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed0497a420364e01b215df934139c6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_919227776db94af8913020b4b92b82fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb742a1622974fb89414389699694950"
          }
        },
        "973a4c38bae64eb49be08ebb803f102f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d9ca606eb344acc9fd5754734c2f605",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 8768093.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a372663e245841c2917b0e11992ea5a4"
          }
        },
        "919227776db94af8913020b4b92b82fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb742a1622974fb89414389699694950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d9ca606eb344acc9fd5754734c2f605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a372663e245841c2917b0e11992ea5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccb3f0b489cb4f50a19841fc48a9df62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e943dfb5fb294116a9d9b8cf872e347a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d820ad29e4948f090589603169cf4e2",
              "IPY_MODEL_0a71738ef4ff49ed89a57ac7d13ec2dd"
            ]
          }
        },
        "e943dfb5fb294116a9d9b8cf872e347a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d820ad29e4948f090589603169cf4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f3bcb845ad142e9b1c411a49d27f1b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74a01964c1ea4afd86d455a7495c9252"
          }
        },
        "0a71738ef4ff49ed89a57ac7d13ec2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25cf1cd3467940da975284e63d98676c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:03&lt;00:00, 8908.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a9d2eaaff66477b8a85fecd49c2651d"
          }
        },
        "9f3bcb845ad142e9b1c411a49d27f1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74a01964c1ea4afd86d455a7495c9252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25cf1cd3467940da975284e63d98676c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a9d2eaaff66477b8a85fecd49c2651d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa08981b9bb846acaab66aeca041599a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e95ae1c533544b2be826724cc59bffd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4cbf49f63cd4778959f681b6df6976e",
              "IPY_MODEL_ea4cc359a8b9411fb3bb54b44b498487"
            ]
          }
        },
        "6e95ae1c533544b2be826724cc59bffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4cbf49f63cd4778959f681b6df6976e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fdfdc92c3d7f49fa85af130561ee39b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18abfc5abc9140bb992d8fc492037eeb"
          }
        },
        "ea4cc359a8b9411fb3bb54b44b498487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c819e72911ea4c779d39d5ca2b5f8ce5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:02&lt;00:00, 1578877.84it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2d5d58fb597419abb4a23112dd8feb7"
          }
        },
        "fdfdc92c3d7f49fa85af130561ee39b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18abfc5abc9140bb992d8fc492037eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c819e72911ea4c779d39d5ca2b5f8ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2d5d58fb597419abb4a23112dd8feb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7385ca9f4fb4bd98ec00ae3048ecbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56b38496b0a94ebdb03a6fc62f26ef6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c215cbffd3fa45b99f201bbfb7d7bad1",
              "IPY_MODEL_fdebc1050faa4e3fb573b775ba0f76b2"
            ]
          }
        },
        "56b38496b0a94ebdb03a6fc62f26ef6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c215cbffd3fa45b99f201bbfb7d7bad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b99c4a69a7834b71a63bcd661d750c6f",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98cdc065e7df415c9c8ee00b1e9e205a"
          }
        },
        "fdebc1050faa4e3fb573b775ba0f76b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c61e6cad9a9349d4bce2af54588c73ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/5148 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91e3cf4e54c74ccea3e454e02f37bd89"
          }
        },
        "b99c4a69a7834b71a63bcd661d750c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98cdc065e7df415c9c8ee00b1e9e205a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c61e6cad9a9349d4bce2af54588c73ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91e3cf4e54c74ccea3e454e02f37bd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SOjAQvMQHe8",
        "colab_type": "text"
      },
      "source": [
        "# Multilayer Perceptron\n",
        "\n",
        "In the previous chapters, we showed how you could implement multiclass logistic regression (also called softmax regression)\n",
        "for classifying images of clothing into the 10 possible categories.\n",
        "To get there, we had to learn how to wrangle data,\n",
        "coerce our outputs into a valid probability distribution (via `softmax`),\n",
        "how to apply an appropriate loss function,\n",
        "and how to optimize over our parameters.\n",
        "Now that we’ve covered these preliminaries,\n",
        "we are free to focus our attention on\n",
        "the more exciting enterprise of designing powerful models\n",
        "using deep neural networks.\n",
        "\n",
        "## Hidden Layers\n",
        "\n",
        "Recall that for linear regression and softmax regression,\n",
        "we mapped our inputs directly to our outputs\n",
        "via a single linear transformation:\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{o}} = \\mathrm{softmax}(\\mathbf{W} \\mathbf{x} + \\mathbf{b})\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dhh9uuwQHfB",
        "colab_type": "text"
      },
      "source": [
        "If our labels really were related to our input data\n",
        "by an approximately linear function, then this approach would be perfect.\n",
        "But linearity is a *strong assumption*.\n",
        "Linearity implies that for whatever target value we are trying to predict,\n",
        "increasing the value of each of our inputs\n",
        "should either drive the value of the output up or drive it down,\n",
        "irrespective of the value of the other inputs.\n",
        "\n",
        "Sometimes this makes sense!\n",
        "Say we are trying to predict whether an individual\n",
        "will or will not repay a loan.\n",
        "We might reasonably imagine that all else being equal,\n",
        "an applicant with a higher income\n",
        "would be more likely to repay than one with a lower income.\n",
        "In these cases, linear models might perform well,\n",
        "and they might even be hard to beat.\n",
        "\n",
        "But what about classifying images in FashionMNIST?\n",
        "Should increasing the intensity of the pixel at location (13,17)\n",
        "always increase the likelihood that the image depicts a pocketbook?\n",
        "That seems ridiculous because we all know\n",
        "that you cannot make sense out of an image\n",
        "without accounting for the interactions among pixels.\n",
        "\n",
        "\n",
        "\n",
        "### From one to many\n",
        "\n",
        "As another case, consider trying to classify images\n",
        "based on whether they depict *cats* or *dogs* given black-and-white images.\n",
        "\n",
        "If we use a linear model, we'd basically be saying that\n",
        "for each pixel, increasing its value (making it more white)\n",
        "must always increase the probability that the image depicts a dog\n",
        "or must always increase the probability that the image depicts a cat.\n",
        "We would be making the absurd assumption that the only requirement\n",
        "for differentiating cats vs. dogs is to assess how bright they are.\n",
        "That approach is doomed to fail in a work\n",
        "that contains both black dogs and black cats,\n",
        "and both white dogs and white cats.\n",
        "\n",
        "Teasing out what is depicted in an image generally requires\n",
        "allowing more complex relationships between our inputs and outputs.\n",
        "Thus we need models capable of discovering patterns\n",
        "that might be characterized by interactions among the many features.\n",
        "We can over come these limitations of linear models\n",
        "and handle a more general class of functions\n",
        "by incorporating one or more hidden layers.\n",
        "The easiest way to do this is to stack\n",
        "many layers of neurons on top of each other.\n",
        "Each layer feeds into the layer above it, until we generate an output.\n",
        "This architecture is commonly called a *multilayer perceptron*,\n",
        "often abbreviated as *MLP*.\n",
        "The neural network diagram for an MLP looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jd5gGCQHfD",
        "colab_type": "text"
      },
      "source": [
        "The multilayer perceptron above has 4 inputs and 3 outputs,\n",
        "and the hidden layer in the middle contains 5 hidden units.\n",
        "Since the input layer does not involve any calculations,\n",
        "building this network would consist of\n",
        "implementing 2 layers of computation.\n",
        "The neurons in the input layer are fully connected\n",
        "to the inputs in the hidden layer.\n",
        "Likewise, the neurons in the hidden layer\n",
        "are fully connected to the neurons in the output layer.\n",
        "\n",
        "\n",
        "### From linear to nonlinear\n",
        "\n",
        "We can write out the calculations that define this one-hidden-layer MLP in mathematical notation as follows:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathbf{h} & = \\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1 \\\\\n",
        "    \\mathbf{o} & = \\mathbf{W}_2 \\mathbf{h} + \\mathbf{b}_2 \\\\\n",
        "    \\hat{\\mathbf{y}} & = \\mathrm{softmax}(\\mathbf{o})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "By adding another layer, we have added two new sets of parameters,\n",
        "but what have we gained in exchange?\n",
        "In the model defined above, we do not achieve anything for our troubles!\n",
        "\n",
        "That's because our hidden units are just a linear function of the inputs\n",
        "and the outputs (pre-softmax) are just a linear function of the hidden units.\n",
        "A linear function of a linear function is itself a linear function.\n",
        "That means that for any values of the weights,\n",
        "we could just collapse out the hidden layer\n",
        "yielding an equivalent single-layer model using\n",
        "$\\mathbf{W} = \\mathbf{W}_2 \\mathbf{W}_1$ and $\\mathbf{b} = \\mathbf{W}_2 \\mathbf{b}_1 + \\mathbf{b}_2$.\n",
        "\n",
        "$$\\mathbf{o} = \\mathbf{W}_2 \\mathbf{h} + \\mathbf{b}_2 = \\mathbf{W}_2 (\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1) + \\mathbf{b}_2 = (\\mathbf{W}_2 \\mathbf{W}_1) \\mathbf{x} + (\\mathbf{W}_2 \\mathbf{b}_1 + \\mathbf{b}_2) = \\mathbf{W} \\mathbf{x} + \\mathbf{b}$$\n",
        "\n",
        "In order to get a benefit from multilayer architectures,\n",
        "we need another key ingredient—a nonlinearity $\\sigma$ to be applied to each of the hidden units after each layer's linear transformation.\n",
        "The most popular choice for the nonlinearity these days is the rectified linear unit (ReLU) $\\mathrm{max}(x,0)$.\n",
        "After incorporating these non-linearities\n",
        "it becomes impossible to merge layers.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathbf{h} & = \\sigma(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1) \\\\\n",
        "    \\mathbf{o} & = \\mathbf{W}_2 \\mathbf{h} + \\mathbf{b}_2 \\\\\n",
        "    \\hat{\\mathbf{y}} & = \\mathrm{softmax}(\\mathbf{o})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Clearly, we could continue stacking such hidden layers,\n",
        "e.g. $\\mathbf{h}_1 = \\sigma(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1)$\n",
        "and $\\mathbf{h}_2 = \\sigma(\\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2)$\n",
        "on top of each other to obtain a true multilayer perceptron.\n",
        "\n",
        "Multilayer perceptrons can account for complex interactions in the inputs\n",
        "because the hidden neurons depend on the values of each of the inputs.\n",
        "It’s easy to design a hidden node that does arbitrary computation,\n",
        "such as, for instance, logical operations on its inputs.\n",
        "Moreover, for certain choices of the activation function\n",
        "it’s widely known that multilayer perceptrons are universal approximators.\n",
        "That means that even for a single-hidden-layer neural network,\n",
        "with enough nodes, and the right set of weights,\n",
        "we can model any function at all!\n",
        "*Actually learning that function is the hard part.*\n",
        "\n",
        "Moreover, just because a single-layer network *can* learn any function\n",
        "doesn't mean that you should try to solve all of your problems with single-layer networks.\n",
        "It turns out that we can approximate many functions\n",
        "much more compactly if we use deeper (vs wider) neural networks.\n",
        "We’ll get more into the math in a subsequent chapter,\n",
        "but for now let’s actually build an MLP.\n",
        "In this example, we’ll implement a multilayer perceptron\n",
        "with two hidden layers and one output layer.\n",
        "\n",
        "### Vectorization and mini-batch\n",
        "\n",
        "As before, by the matrix $\\mathbf{X}$, we denote a mini-batch of inputs.\n",
        "The calculations to produce outputs from an MLP with two hidden layers\n",
        "can thus be expressed:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathbf{H}_1 & = \\sigma(\\mathbf{W}_1 \\mathbf{X} + \\mathbf{b}_1) \\\\\n",
        "    \\mathbf{H}_2 & = \\sigma(\\mathbf{W}_2 \\mathbf{H}_1 + \\mathbf{b}_2) \\\\\n",
        "    \\mathbf{O} & = \\mathrm{softmax}(\\mathbf{W}_3 \\mathbf{H}_2 + \\mathbf{b}_3)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "With some abuse of notation, we define the nonlinearity $\\sigma$\n",
        "to apply to its inputs on a row-wise fashion, i.e. one observation at a time.\n",
        "Note that we are also using the notation for *softmax* in the same way to denote a row-wise operation.\n",
        "Often, as in this chapter, the activation functions that we apply to hidden layers are not merely row-wise, but component wise.\n",
        "That means that after computing the linear portion of the layer,\n",
        "we can calculate each nodes activation without looking at the values taken by the other hidden units.\n",
        "This is true for most activation functions\n",
        "(the batch normalization operation will be introduced in :numref:`chapter_batch_norm` is a notable exception to that rule).\n",
        "\n",
        "## Activation Functions\n",
        "\n",
        "Because they are so fundamental to deep learning, before going further,\n",
        "let's take a brief look at some common activation functions.\n",
        "\n",
        "### ReLU Function\n",
        "\n",
        "As stated above, the most popular choice,\n",
        "due to its simplicity of implementation\n",
        "and its efficacy in training is the rectified linear unit (ReLU).\n",
        "ReLUs provide a very simple nonlinear transformation.\n",
        "Given the element $z$, the function is defined\n",
        "as the maximum of that element and 0.\n",
        "\n",
        "$$\\mathrm{ReLU}(z) = \\max(z, 0).$$\n",
        "\n",
        "It can be understood that the ReLU function retains only positive elements and discards negative elements (setting those nodes to 0).\n",
        "To get a better idea of what it looks like, we can plot it.\n",
        "For convenience, we define a plotting function `xyplot`\n",
        "to take care of the groundwork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUOI-LhGQHfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def xyplot(x_vals,y_vals,name):\n",
        "    x_vals = x_vals.detach().numpy() # we can't directly use var.numpy() because varibles might \n",
        "    y_vals = y_vals.detach().numpy() # already required grad.,thus using var.detach().numpy() \n",
        "    plt.plot(x_vals,y_vals) \n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel(name+'(x)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSWo97pJQHfG",
        "colab_type": "text"
      },
      "source": [
        "Since relu is commomly used as activation function, PyTorch supports\n",
        "the `relu` function as a basic native operator.\n",
        "As you can see, the activation function is piece-wise linear.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvKuNcq1QHfG",
        "colab_type": "code",
        "outputId": "1cadc819-6958-48b3-b4f0-5ffa75215ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x = Variable(torch.arange(-8.0,8.0,0.1,dtype=torch.float32).reshape(int(16/0.1),1), requires_grad=True)\n",
        "y = torch.nn.functional.relu(x)\n",
        "xyplot(x,y,'relu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAzWGZdeQHfJ",
        "colab_type": "text"
      },
      "source": [
        "When the input is negative, the derivative of ReLU function is 0\n",
        "and when the input is positive, the derivative of ReLU function is 1.\n",
        "Note that the ReLU function is not differentiable\n",
        "when the input takes value precisely equal to  0.\n",
        "In these cases, we go with the left-hand-side (LHS) derivative\n",
        "and say that the derivative is 0 when the input is 0.\n",
        "We can get away with this because the input may never actually be zero.\n",
        "There's an old adage that if subtle boundary conditions matter,\n",
        "we are probably doing (*real*) mathematics, not engineering.\n",
        "That conventional wisdom may apply here.\n",
        "See the derivative of the ReLU function plotted below.\n",
        "\n",
        "When we use .backward(), by default it is .backward(torch.Tensor([1])).This is useful when we are dealing with single scalar input.But here we are dealing with a vector input so we have to use this snippet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNiVPTVjQHfJ",
        "colab_type": "code",
        "outputId": "a2b9c31f-39a2-4109-b3e2-1662f6b19df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "y.backward(torch.ones_like(x), retain_graph=True)\n",
        "xyplot(x,x.grad,\"grad of relu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pry_-qSpQHfM",
        "colab_type": "text"
      },
      "source": [
        "Note that there are many variants to the ReLU function, such as the parameterized ReLU (pReLU) of [He et al., 2015](https://arxiv.org/abs/1502.01852). This variation adds a linear term to the ReLU, so some information still gets through, even when the argument is negative.\n",
        "\n",
        "$$\\mathrm{pReLU}(x) = \\max(0, x) + \\alpha \\min(0, x)$$\n",
        "\n",
        "The reason for using the ReLU is that its derivatives are particularly well behaved - either they vanish or they just let the argument through. This makes optimization better behaved and it reduces the issue of the vanishing gradient problem (more on this later).\n",
        "\n",
        "### Sigmoid Function\n",
        "\n",
        "The sigmoid function transforms its inputs which take values in $\\mathbb{R}$ to the interval $(0,1)$.\n",
        "For that reason, the sigmoid is often called a *squashing* function:\n",
        "it squashes any input in the range (-inf, inf)\n",
        "to some value in the range (0,1).\n",
        "\n",
        "$$\\mathrm{sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}.$$\n",
        "\n",
        "In the earliest neural networks, scientists\n",
        "were interested in modeling biological neurons\n",
        "which either *fire* or *don't fire*.\n",
        "Thus the pioneers of this field, going all the way back to McCulloch and Pitts in the 1940s, were focused on thresholding units.\n",
        "A thresholding function takes either value $0$\n",
        "(if the input is below the threshold)\n",
        "or value $1$ (if the input exceeds the threshold)\n",
        "\n",
        "\n",
        "When attention shifted to gradient based learning,\n",
        "the sigmoid function was a natural choice\n",
        "because it is a smooth, differentiable approximation to a thresholding unit.\n",
        "Sigmoids are still common as activation functions on the output units,\n",
        "when we want to interpret the outputs as probabilities\n",
        "for binary classification problems\n",
        "(you can think of the sigmoid as a special case of the softmax)\n",
        "but the sigmoid has mostly been replaced by the simpler and easier to train ReLU for most use in hidden layers.\n",
        "In the \"Recurrent Neural Network\" chapter, we will describe\n",
        "how sigmoid units can be used to control\n",
        "the flow of information in a neural network\n",
        "thanks to its capacity to transform the value range between 0 and 1.\n",
        "\n",
        "See the sigmoid function plotted below.\n",
        "When the input is close to 0, the sigmoid function\n",
        "approaches a linear transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuN7nVQoQHfN",
        "colab_type": "code",
        "outputId": "917b1325-5663-43b5-da13-cd568125a226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x = Variable(torch.arange(-8.0,8.0,0.1, dtype=torch.float32).reshape(int(16/0.1),1), requires_grad=True)\n",
        "y = torch.sigmoid(x)\n",
        "xyplot(x,y,'sigmoid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTyTY-_AQHfP",
        "colab_type": "text"
      },
      "source": [
        "The derivative of sigmoid function is given by the following equation:\n",
        "\n",
        "$$\\frac{d}{dx} \\mathrm{sigmoid}(x) = \\frac{\\exp(-x)}{(1 + \\exp(-x))^2} = \\mathrm{sigmoid}(x)\\left(1-\\mathrm{sigmoid}(x)\\right).$$\n",
        "\n",
        "\n",
        "The derivative of sigmoid function is plotted below.\n",
        "Note that when the input is 0, the derivative of the sigmoid function\n",
        "reaches a maximum of 0.25. As the input diverges from 0 in either direction, the derivative approaches 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR5YyvIZQHfQ",
        "colab_type": "code",
        "outputId": "1fbea752-779d-43d7-94ed-25f0fa16f7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "y.backward(torch.ones_like(x), retain_graph=True)\n",
        "xyplot(x,x.grad,'grad of sigmoid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQSTzchhQHfS",
        "colab_type": "text"
      },
      "source": [
        "### Tanh Function\n",
        "\n",
        "Like the sigmoid function, the tanh (Hyperbolic Tangent)\n",
        "function also squashes its inputs,\n",
        "transforms them into elements on the interval between -1 and 1:\n",
        "\n",
        "$$\\text{tanh}(x) = \\frac{1 - \\exp(-2x)}{1 + \\exp(-2x)}.$$\n",
        "\n",
        "We plot the tanh function blow. Note that as the input nears 0, the tanh function approaches a linear transformation. Although the shape of the function is similar to the sigmoid function, the tanh function exhibits point symmetry about the origin of the coordinate system.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjFZxPHnQHfS",
        "colab_type": "code",
        "outputId": "01ae7858-d15a-48fa-92f2-96182cb5c8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x = Variable(torch.arange(-8.0,8.0,0.1, dtype=torch.float32).reshape(int(16/0.1),1), requires_grad=True)\n",
        "y = torch.tanh(x)\n",
        "xyplot(x,y,\"tanh\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXRd5X3u8e8jyZbn2djGM2AmY7BBOGCagcGJob04c0ga6kx1mhuSJp0CYTXJpU1DmtvStGU1cQktSQikIUnxDRDCmDRhqGVjbNnGsWyMJdlgeZA8yNb4u3+cbXosJFuWdLTPkZ7PWmdpj+c8Bkk/vfvd+30VEZiZmZ2qorQDmJlZYXIBMTOzbnEBMTOzbnEBMTOzbnEBMTOzbilJO0BfmjBhQsyaNSvtGGZmBWX16tV7ImJi++0DqoDMmjWL8vLytGOYmRUUSa90tN2XsMzMrFtcQMzMrFtcQMzMrFtcQMzMrFtcQMzMrFtSLSCS7pa0W1JFJ/sl6R8lVUpaJ+nirH3LJG1JXsv6LrWZmUH6LZB/B5acYP+1wJzktRz4FwBJ44AvA28CFgJfljQ2p0nNzOw4qT4HEhG/kjTrBIcsBb4bmTHnn5M0RtIU4G3AYxGxD0DSY2QK0X25TWxmPRERNLa00dDUSkNTC0eaWmloauVocyutbUFzW9Da1kZLa9DaFrS0BS3t1lvbgrYIIiCS98y8d/IZZO/LrB+3P+tcso7J3tZH/zH68tNYtmgW40eU9up75vuDhFOBqqz16mRbZ9vfQNJyMq0XZsyYkZuUZgNYRFB7qJEdexvYvreB1w4cZe+hJvYebmTvoSb2HGpk3+EmDje2cKS5lTZPQfQ6qe8+6/r5UwdcAemxiFgBrAAoKyvzt65ZD7S1BZW1h3ixqo71NfW8WF3PltcO0tDUetxxwwcXM35EKeNHDGba2KFcOG00I0oHMWxwMUMHFzMseQ0dXMKwQZltJUWipFgUFxW9vlxSdPx6cZEoVuYrgBAo84tYgHRs+7FtOu6XdPa2Do/vy9/o/UC+F5AaYHrW+rRkWw2Zy1jZ25/us1RmA8iRplZ+U7mHJ156jcc37ab2YCOQKRIXTB3N+8umM2v8MGZOGM7MccM4fcxQhgwqTjm19YV8LyArgZsk3U+mw7w+InZJehT4m6yO87cDt6QV0qw/WrNjP/c+t4OH1u/kaHMbI0pLeOvZE3nbORNZMGMsZ0wYTlGR/2IfyFItIJLuI9OSmCCpmsydVYMAIuJbwMPAdUAl0AB8NNm3T9JfAauSt7rtWIe6mfXMr7fs4R+f2MJ/b9/H8MHFvGvBNK6bN5k3zR7P4JK0b9y0fKLo4zsB0lRWVhYejdesY9v3HOa2n23kyZd2M3nUED751jN4X9l0RpTm+4UKyzVJqyOirP12f2eYDXARwT3PbOdvHnmJQUXii9edy7JFsygtcT+GnZgLiNkAduBoM5+7fy1PvrSbq849jdvfPY/TRg1JO5YVCBcQswGqal8DH79nFdtqD3Pb0rnceNlM38Zqp8QFxGwAennPYT7w7Wc52tzKdz++kEVnTkg7khUgFxCzAWbH3gY+9K/P0doWPPCpRZw9aWTakaxAuYCYDSD7Dzdx493Pc6S5lfv+8DIXD+sR39RtNkA0t7bx6R+sYVfdUb6z7FLOmzIq7UhW4NwCMRsgvv7ISzyzdS/feO+FXDLTsx9Yz7kFYjYA/KZyD3f9+mVuvGwm7yubfvITzLrABcSsn6s/0syf/ehFzpg4nC9ed17acawf8SUss37uaw9vYvfBRn7yqUUMHeyny633uAVi1o+tq67jh+VVfOyKWVw0fUzacayfcQEx66fa2oKvrNzA+OGlfPbqOWnHsX7IBcSsn1r54k7W7KjjC0vOYeSQQWnHsX7IBcSsH2ppbeOOx3/L3NNH8Z6Lp6Udx/opFxCzfujBtTt5ZW8Df3z1HM8aaDmTagGRtETSZkmVkm7uYP8dktYmr99Kqsva15q1b2XfJjfLXy2tbfzzU5WcP2UUi8+flHYc68dSu41XUjFwJ7AYqAZWSVoZERuPHRMRn886/jPAgqy3OBIR8/sqr1mheGj9Ll7ec5hv33iJh2e3nEqzBbIQqIyIbRHRBNwPLD3B8R8E7uuTZGYFKiL4zq9f5syJw1l8nlsflltpFpCpQFXWenWy7Q0kzQRmA09mbR4iqVzSc5Le2dmHSFqeHFdeW1vbG7nN8tYLVXWsq67nI4tmue/Dcq5QOtFvAB6IiNasbTOTSd4/BPyDpDM7OjEiVkREWUSUTZw4sS+ymqXmnme2M7K0hHf7zivrA2kWkBoge1S3acm2jtxAu8tXEVGTfN0GPM3x/SNmA87uA0d5aN0u3lc2neGlHqXIci/NArIKmCNptqTBZIrEG+6mknQuMBZ4NmvbWEmlyfIE4ApgY/tzzQaSH62upqUtuPHymWlHsQEitT9TIqJF0k3Ao0AxcHdEbJB0G1AeEceKyQ3A/RERWaefB3xbUhuZInh79t1bZgNNRPDjNdUsnDWO2ROGpx3HBohU27kR8TDwcLttX2q3/pUOznsGmJfTcGYFZG1VHdtqD/PJt5yRdhQbQAqlE93MTuAna2oYMqiI6+ZNSTuKDSAuIGYFrrGllZUv7uQdcyd70ETrUy4gZgXul5trqT/S7Ft3rc+5gJgVuEcqXmXMsEEsOnN82lFsgHEBMStgTS1tPL7pNRafN4lBxf5xtr7l7zizAvabrXs4eLSFa+dNTjuKDUAuIGYF7JH1uxhZWsIVZ01IO4oNQC4gZgWqpbWNxza+xlXnnUZpSXHacWwAcgExK1Dlr+xnf0Mz75jry1eWDhcQswL11ObdlBSJN8/x5StLhwuIWYH65eZaLp01zg8PWmpcQMwK0M66I7z06kGuPNdz3Fh6XEDMCtDTmzOza77tnNNSTmIDmQuIWQF6evNupo4ZypzTRqQdxQYwFxCzAtPU0sZvKvfwtnMmInnec0uPC4hZgVlbVcfhplbecrb7PyxdqRYQSUskbZZUKenmDvZ/RFKtpLXJ6xNZ+5ZJ2pK8lvVtcrP0PLN1D0WCy87w4ImWrtRmJJRUDNwJLAaqgVWSVnYwNe0PI+KmdueOA74MlAEBrE7O3d8H0c1S9czWvVwwdTSjh/r2XUtXmi2QhUBlRGyLiCbgfmBpF899B/BYROxLisZjwJIc5TTLGw1NLbywYz+Xe+h2ywNpFpCpQFXWenWyrb33SFon6QFJ00/xXCQtl1Quqby2trY3cpulpnz7fppbg0Vn+ulzS1++d6L/P2BWRFxIppVxz6m+QUSsiIiyiCibONGdjlbYntm6l0HF4tJZY9OOYpZqAakBpmetT0u2vS4i9kZEY7J6F3BJV88164+e3bqHBdPHMmxwat2XZq9Ls4CsAuZImi1pMHADsDL7AElTslavBzYly48Cb5c0VtJY4O3JNrN+6+DRZtbX1HOZ+z8sT6T2Z0xEtEi6icwv/mLg7ojYIOk2oDwiVgKflXQ90ALsAz6SnLtP0l+RKUIAt0XEvj7/R5j1odWv7KctYOGscWlHMQNSLCAAEfEw8HC7bV/KWr4FuKWTc+8G7s5pQLM8Ur59P8VFYsGMMWlHMQPyvxPdzBKrtu9j7umjGF7q/g/LDy4gZgWgsaWVtVV1lM305SvLHy4gZgWgouYAjS1tLJzt23ctf7iAmBWA8u2Ze0QucQvE8ogLiFkBWLV9H7MnDGfiyNK0o5i9zgXELM9FBKtf2U/ZTF++svziAmKW53bsa2B/QzMLZriAWH5xATHLc2ur6gCYP93Pf1h+cQExy3Nrq+oYMqiIsyd5/nPLLy4gZnnuxao65k0dTUmxf1wtv/g70iyPNbe2UbHzABdN8+Uryz8uIGZ57KVdB2lqaWO+x7+yPOQCYpbH1lZnOtDdArF85AJilsderKpj/PDBTBs7NO0oZm/gAmKWx16sqmP+9DFISjuK2RukWkAkLZG0WVKlpJs72P8nkjZKWifpCUkzs/a1SlqbvFa2P9es0B082kxl7SEu8vMflqdSm1hAUjFwJ7AYqAZWSVoZERuzDnsBKIuIBkmfAv4W+ECy70hEzO/T0GZ9aH11PRG4gFjeSrMFshCojIhtEdEE3A8szT4gIp6KiIZk9TlgWh9nNEvN/3Sgj045iVnH0iwgU4GqrPXqZFtnPg48krU+RFK5pOckvbOzkyQtT44rr62t7Vlisz60dkcdsycMZ8ywwWlHMetQQcyNKenDQBnw1qzNMyOiRtIZwJOS1kfE1vbnRsQKYAVAWVlZ9Elgs17wYnUdl58xPu0YZp1KswVSA0zPWp+WbDuOpGuAW4HrI6Lx2PaIqEm+bgOeBhbkMqxZX3q1/iivHWh0/4fltTQLyCpgjqTZkgYDNwDH3U0laQHwbTLFY3fW9rGSSpPlCcAVQHbnu1lB8wi8VghSu4QVES2SbgIeBYqBuyNig6TbgPKIWAl8AxgB/Ci5D35HRFwPnAd8W1IbmSJ4e7u7t8wK2tqqOgYVi/OmjEo7ilmnUu0DiYiHgYfbbftS1vI1nZz3DDAvt+nM0rOuuo5zJ49iyKDitKOYdcpPopvlmYigoqaeeb591/KcC4hZnqnad4QDR1u44HQXEMtvLiBmeaZiZz0A86a6gFh+cwExyzMVNfWUFImzJ3sKW8tvXepEl1QGvBk4HTgCVACPRcT+HGYzG5Aqdh7g7EkjKS1xB7rltxO2QCR9VNIa4BZgKLAZ2A38DvC4pHskzch9TLOBISLYUFPPBVN9+67lv5O1QIYBV0TEkY52SpoPzAF29HYws4Ho1QNH2Xu4iQvc/2EF4IQFJCLu7GyfpMERsbb3I5kNXBU1BwCY6zuwrAB0qRNd0tOSZmWtLyQzFImZ9aKKmnqKBOdNGZl2FLOT6uqT6F8Dfi7pH8kMuX4t8NGcpTIboDbsrOfMiSMYNrggBsq2Aa5L36UR8aikPwIeA/YACyLi1ZwmMxuA1tfUs+jMCWnHMOuSrl7C+kvgn4C3AF8Bnpb0uznMZTbg7D6YGcJ97um+A8sKQ1fbyeOBhcndWM9K+jlwF/BQzpKZDTAbdmY60H0HlhWKrl7C+ly79VeAxTlJZDZAbajJDGFyvlsgViBO9iDhv0rqcNh0ScMlfUzS7+cmmtnAUlFzgFnjhzFqyKC0o5h1yclaIHcCf5kUkQqgFhhC5uHBUcDdwL05TWg2QFTsrPcMhFZQTtgCiYi1EfF+4FIyxeS/yEw7+4mIuCgivpk9T/mpkrRE0mZJlZJu7mB/qaQfJvufb/csyi3J9s2S3tHdDGb5oK6hier9R9z/YQWlq30gh4Cne/ODJRWTKUqLgWpglaSV7aam/TiwPyLOknQD8HXgA5LOJzOH+lwyAzw+LunsiGjtzYxmfeX1DnQ/gW4FpKu38V4h6TFJv5W0TdLLkrb18LMXApURsS0imoD7gaXtjlkK3JMsPwBcrczk6EuB+yOiMSJeBiqT9zMrSBVJB7pv4bVC0tXbeL8DfB5YDfTWX/lTgaqs9WrgTZ0dExEtkurJ3FI8FXiu3blTO/oQScuB5QAzZnjgYMtPFTsPMHXMUMYOH5x2FLMu62oBqY+IR3KaJEciYgWwAqCsrCxSjmPWIQ/hboXohAVE0sXJ4lOSvgH8BHi90zwi1vTgs2uA6Vnr05JtHR1TLakEGA3s7eK5ZgXh4NFmtu05zLsWdNiINstbJ2uB/F279bKs5QCu6sFnrwLmSJpN5pf/DcCH2h2zElgGPAu8F3gyIkLSSuAHkv6eTCf6HOC/e5DFLDUb/QS6FaiTzQdyZa4+OOnTuAl4FCgG7o6IDZJuA8ojYiWZvpfvSaoE9pEpMiTH/QewEWgBPu07sKxQVSQFZK4vYVmB6eqc6KXAe4BZ2edExG09+fCIeBh4uN22L2UtHwXe18m5XwW+2pPPN8sHG2rqOW1kKaeNHJJ2FLNT0tVO9AeBejJ3YXX7wUEze6OKnfW+fGUFqasFZFpELMlpErMB6EhTK5W7D7Fk7uS0o5idsi49SAg809mgimbWfZtePUBbwFy3QKwAdbUF8jvARyS9TOYSloCIiAtzlsxsADg2hPs8FxArQF0tINfmNIXZALWuup5xwwczZbQ70K3wdHUwxVcAJJ1GZjh3M+sF62vqmTd1NJkh3swKS1cHU7xe0hbgZeCXwHagIIc2McsXR5pa2bL7EBdO8+UrK0xd7UT/K+Ay4LcRMRu4muMHMzSzU7Rx1wFa28L9H1awulpAmiNiL1AkqSginuL4YU3M7BQdG8J9nlsgVqC62oleJ2kE8CvgXkm7gUO5i2XW/62rrmfCiFImj3K3ohWmrhaQF4EGMnOC/D6ZUXFH5CqU2UCwvqaOC6e5A90KV1cLyJUR0Qa0kcwQKGldzlKZ9XMNTS1U7j7EtRdMSTuKWbedbD6QTwH/GzizXcEYCfwml8HM+rONOzNPoLsD3QrZyVogPyBzu+7XgJuzth+MiH05S2XWz62rdge6Fb6TzQdST2YU3g/2TRyzgWF9TT2TRpUyyR3oVsC6ehuvmfWizBPoY9KOYdYjqRQQSeMkPSZpS/J1bAfHzJf0rKQNktZJ+kDWvn+X9LKktclrft/+C8y671BjC1trD7n/wwpeWi2Qm4EnImIO8ATH968c0wD8QUTMBZYA/yAp+0+2P4+I+clrbe4jm/WODTX1ROAhTKzgpVVAlpLcDpx8fWf7AyLitxGxJVneCewGJvZZQrMcWZ88ge5ZCK3QpVVAJkXErmT5VWDSiQ6WtBAYDGzN2vzV5NLWHcmc7Z2du1xSuaTy2traHgc366n1NfWcPnoIE0d2+m1rVhByVkAkPS6pooPX0uzjIiKAOMH7TAG+B3w0eZgR4BbgXOBSYBzwhc7Oj4gVEVEWEWUTJ7oBY+lbX13v23etX+jqk+inLCKu6WyfpNckTYmIXUmB2N3JcaOAh4BbI+L10X+zWi+Nkv4N+LNejG6WMweONrNtz2HeffHUtKOY9Vhal7BWAsuS5WXAg+0PkDQY+Cnw3Yh4oN2+KclXkek/qchpWrNesqHmAADzpvkWXit8aRWQ24HFySRV1yTrSCqTdFdyzPuBt5CZi7397br3SloPrAcmAH/dt/HNumdtVR0AF7oD3fqBnF3COpFkbpGrO9heDnwiWf4+8P1Ozr8qpwHNcuSFHfs5Y8Jwxg4fnHYUsx7zk+hmfSQieKGqjvkzfPnK+gcXELM+UlN3hNqDjSyY7gJi/YMLiFkfeWFHpv9jwYw3jNxjVpBcQMz6yAs76hgyqIhzJo9MO4pZr3ABMesjL1Tt58KpYxhU7B876x/8nWzWBxpbWtlQc4AF7kC3fsQFxKwPbNh5gKbWNua7A936ERcQsz5Qvj0zA/Qls9yBbv2HC4hZH1i1fT+zxg/jtJGewtb6DxcQsxxrawvKt++jbNa4tKOY9SoXELMc27bnEPsbmlnoAmL9jAuIWY6t2r4fgDL3f1g/4wJilmOrXt7HhBGDmT1heNpRzHqVC4hZjq16ZR9lM8eRmb7GrP9wATHLoVfrj1K174gvX1m/lEoBkTRO0mOStiRfO/zpktSaNZnUyqztsyU9L6lS0g+T2QvN8s6z2/YAcNkZ41NOYtb70mqB3Aw8ERFzgCeS9Y4ciYj5yev6rO1fB+6IiLOA/cDHcxvXrHueqdzL6KGDOH/KqLSjmPW6tArIUuCeZPkeMvOad0kyD/pVwLF50k/pfLO+EhE8s3Uvl58xnqIi939Y/5NWAZkUEbuS5VeBSZ0cN0RSuaTnJB0rEuOBuohoSdargamdfZCk5cl7lNfW1vZKeLOuqNp3hJq6Iyw6y5evrH/K2Zzokh4HJnew69bslYgISdHJ28yMiBpJZwBPSloP1J9KjohYAawAKCsr6+xzzHrdb7Zm+j8WnekCYv1TzgpIRFzT2T5Jr0maEhG7JE0BdnfyHjXJ122SngYWAD8GxkgqSVoh04CaXv8HmPXQM1v3ctrIUs6cOCLtKGY5kdYlrJXAsmR5GfBg+wMkjZVUmixPAK4ANkZEAE8B7z3R+WZpigie3bqHRWeO9/Mf1m+lVUBuBxZL2gJck6wjqUzSXckx5wHlkl4kUzBuj4iNyb4vAH8iqZJMn8h3+jS92Uls2nWQPYeaWHTWhLSjmOVMzi5hnUhE7AWu7mB7OfCJZPkZYF4n528DFuYyo1lPPLU5c1X2bWdPTDmJWe74SXSzHHh6827mnj6K00Z5/g/rv1xAzHpZfUMza3bUceU5p6UdxSynXEDMetl/VdbS2hZcea4vX1n/5gJi1sue3lzL6KGDmD/dAyha/+YCYtaL2tqCpzfX8pazJ1Ls4Uusn3MBMetFa3bsZ8+hRq45z/0f1v+5gJj1okcqXmVwcRFXnesCYv2fC4hZL4kIfl7xKm+eM4GRQwalHccs51xAzHrJuup6auqOsOSCjsYQNet/XEDMeskjFa9SUiQWn9/Z7ARm/YsLiFkviAgeqdjF5WeOZ8wwz7BsA4MLiFkvWLNjP6/sbeD6i05PO4pZn3EBMesFD6yuYeigYq6dNyXtKGZ9xgXErIeONrfys3U7WXLBZEaUpjLAtVkqXEDMeuixja9x8GgL77l4WtpRzPqUC4hZDz2wupopo4dwuec+twEmlQIiaZykxyRtSb6+YdQ5SVdKWpv1Oirpncm+f5f0cta++X3/rzCD7XsO86sttbyvbLrHvrIBJ60WyM3AExExB3giWT9ORDwVEfMjYj5wFdAA/CLrkD8/tj8i1vZJarN2vvvsKxRLfPhNM9KOYtbn0iogS4F7kuV7gHee5Pj3Ao9ERENOU5mdgsONLfyovIrr5k3xzIM2IKVVQCZFxK5k+VXgZI/u3gDc127bVyWtk3SHpNLOTpS0XFK5pPLa2toeRDY73k/WVHOwsYVli2alHcUsFTkrIJIel1TRwWtp9nEREUCc4H2mAPOAR7M23wKcC1wKjAO+0Nn5EbEiIsoiomziRM8QZ72jpbWNu379MhdOG83FM8akHccsFTm7aT0irulsn6TXJE2JiF1Jgdh9grd6P/DTiGjOeu9jrZdGSf8G/FmvhDbrov9cu5NX9jaw4sZLkNx5bgNTWpewVgLLkuVlwIMnOPaDtLt8lRQdlPnJfSdQkYOMZh1qaW3jn57cwvlTRnngRBvQ0iogtwOLJW0BrknWkVQm6a5jB0maBUwHftnu/HslrQfWAxOAv+6DzGYAPJi0Pj53zRy3PmxAS2XchYjYC1zdwfZy4BNZ69uBqR0cd1Uu85l1pqGphb/7xWYumOrWh5mfRDc7Bd96eis764/y5f81160PG/BcQMy6qGpfA9/+1Tauv+h0Lp01Lu04ZqlzATHrgojg1v+soEjiluvOTTuOWV5wATHrgu8/v4Nf/baWL153LlNGD007jllecAExO4lttYf4m4c28eY5E/jwZTPTjmOWN1xAzE7g4NFmPvm91ZQOKuIb773IHedmWTx9mlkn2tqCz/9wLdv2HOZ7H1vI5NEeMNEsm1sgZh2ICL68cgOPb9rNl37vfBadNSHtSGZ5xwXErJ2I4LafbeR7z73CJ99yBn9wufs9zDriS1hmWZpa2vjiT9fzwOpqPnbFbG6+9lz3e5h1wgXELFF7sJHP3LeG57bt47NXz+HzHuvK7IRcQMyAJza9xl88sI5DjS3c8YGLeNeCaWlHMst7LiA2oFXvb+CrD23ikYpXOXfySO5bfhlnTxqZdiyzguACYgNSTd0RvvX0Vn5YXkWR4E8Xn83yt55BaUlx2tHMCoYLiA0YR5pa+dWWWn5UXs2TL71GcZF47yXTuOmqOUwd4+FJzE6VC4j1WxFB1b4j/LpyD09seo1fV+6hsaWNCSMG88m3nsmHL5vpwmHWA6kUEEnvA74CnAcsTCaS6ui4JcA3gWLgrog4NnPhbOB+YDywGrgxIpr6ILrloYhgf0Mz2/ceZsfeBrbsPsi66nrW19RT19AMwLSxQ/ngwhksPn8SC2ePY1CxH4Ey66m0WiAVwLuBb3d2gKRi4E5gMVANrJK0MiI2Al8H7oiI+yV9C/g48C+5j229ISJoaQtaWoPmtjZaWoOW1jaa25KvrcHR5lYONbZw6GgLh5ta/me5sYWDjS3sOdRE7cGj1B5sZPeBRg42trz+/sVF4pxJI1kydzIXThvDJTPHcvakEb4l16yXpTWl7SbgZD/QC4HKiNiWHHs/sFTSJuAq4EPJcfeQac3krIDc+tP1PP/yPiDzy++YyD4oOlw87vg37sveHh1vP/70Dt+3s/c84ft2ek5Xju/iv6ldxpbWoKUtUyC6S4IRg0sYP2IwE0eWcs7kkfzOWROYMX44M8cNY+b4YUwfN4whg9wZbpZr+dwHMhWoylqvBt5E5rJVXUS0ZG1/w7zpx0haDiwHmDFjRreCnD5mKOdk39qpDhePK4jHb2+XqQvnHP8ZWcd0+tkdH/+GfZ18yKm+b1f/TdkGFYuS4iIGFWW+lhSLwcVFlCTrg4pFSVFm+9BBxYwoLWF4aQkjhpQwojTzGjqomKIityTM8kHOCoikx4HJHey6NSIezNXnthcRK4AVAGVlZd360/fTV57Vq5nMzPqDnBWQiLimh29RA0zPWp+WbNsLjJFUkrRCjm03M7M+lM+3oqwC5kiaLWkwcAOwMjIX1p8C3psctwzosxaNmZllpFJAJL1LUjVwOfCQpEeT7adLehggaV3cBDwKbAL+IyI2JG/xBeBPJFWS6RP5Tl//G8zMBjq1v6OmPysrK4vy8g4fOTEzs05IWh0RZe235/MlLDMzy2MuIGZm1i0uIGZm1i0uIGZm1i0DqhNdUi3wSjdPnwDs6cU4vSVfc0H+ZnOuU5OvuSB/s/W3XDMjYmL7jQOqgPSEpPKO7kJIW77mgvzN5lynJl9zQf5mGyi5fAnLzMy6xQXEzMy6xQWk61akHaAT+ZoL8jebc52afM0F+ZttQORyH4iZmXWLWyBmZtYtLiBmZtYtLiCnQNJ8Sc9JWiupXNLCtDMdI+kzkl6StEHS36adJ5ukP5UUkiakneUYSd9I/nutk/RTSWNSzrNE0mZJlZJuTjPLMZKmS3pK0khP/IkAAARqSURBVMbk++qP086UTVKxpBck/SztLNkkjZH0QPL9tUnS5WlnApD0+eT/Y4Wk+yQN6el7uoCcmr8F/k9EzAe+lKynTtKVwFLgooiYC/zflCO9TtJ04O3AjrSztPMYcEFEXAj8FrglrSCSioE7gWuB84EPSjo/rTxZWoA/jYjzgcuAT+dJrmP+mMxUD/nmm8DPI+Jc4CLyIKOkqcBngbKIuAAoJjPHUo+4gJyaAEYly6OBnSlmyfYp4PaIaASIiN0p58l2B/AXZP7b5Y2I+EUy5wzAc2RmtkzLQqAyIrZFRBNwP5k/CFIVEbsiYk2yfJDML8Kp6abKkDQN+F3grrSzZJM0GngLyRxFEdEUEXXppnpdCTBUUgkwjF74/eUCcmo+B3xDUhWZv/JT+6u1nbOBN0t6XtIvJV2adiAASUuBmoh4Me0sJ/Ex4JEUP38qUJW1Xk2e/KI+RtIsYAHwfLpJXvcPZP4waUs7SDuzgVrg35LLa3dJGp52qIioIfM7awewC6iPiF/09H1zNid6oZL0ODC5g123AlcDn4+IH0t6P5m/Mno693tv5CoBxpG5zHAp8B+Szog+uEf7JLm+SObyVSpOlC0iHkyOuZXMpZp7+zJbIZE0Avgx8LmIOJAHeX4P2B0RqyW9Le087ZQAFwOfiYjnJX0TuBn4yzRDSRpLplU7G6gDfiTpwxHx/Z68rwtIOxHRaUGQ9F0y110BfkQfNp9PkutTwE+SgvHfktrIDJpWm1YuSfPIfLO+KAkyl4jWSFoYEa/mOteJsh0j6SPA7wFX90WxPYEaYHrW+rRkW+okDSJTPO6NiJ+knSdxBXC9pOuAIcAoSd+PiA+nnAsyrcfqiDjWUnuATAFJ2zXAyxFRCyDpJ8AioEcFxJewTs1O4K3J8lXAlhSzZPtP4EoASWcDg0l5JNCIWB8Rp0XErIiYReYH6+K+Kh4nI2kJmUsg10dEQ8pxVgFzJM2WNJhM5+bKlDOhTOX/DrApIv4+7TzHRMQtETEt+b66AXgyT4oHyfd3laRzkk1XAxtTjHTMDuAyScOS/69X0wud+26BnJo/BL6ZdEIdBZannOeYu4G7JVUATcCylP+iLgT/DJQCjyUtpOci4o/SCBIRLZJuAh4lc3fM3RGxIY0s7VwB3Aisl7Q22fbFiHg4xUyF4DPAvckfA9uAj6ach+Ry2gPAGjKXbF+gF4Y18VAmZmbWLb6EZWZm3eICYmZm3eICYmZm3eICYmZm3eICYmZm3eICYmZm3eICYmZm3eICYpYiSZcmc5IMkTQ8ma/hgrRzmXWFHyQ0S5mkvyYzptNQMuMofS3lSGZd4gJilrJkyItVZIbHWRQRrSlHMusSX8IyS994YAQwkkxLxKwguAViljJJK8nMQjgbmBIRN6UcyaxLPBqvWYok/QHQHBE/SOZGf0bSVRHxZNrZzE7GLRAzM+sW94GYmVm3uICYmVm3uICYmVm3uICYmVm3uICYmVm3uICYmVm3uICYmVm3/H9ME/dPrso37QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgSsaFgQ6yz",
        "colab_type": "text"
      },
      "source": [
        "The derivative of the Tanh function is:\n",
        "\n",
        "$$\\frac{d}{dx} \\mathrm{tanh}(x) = 1 - \\mathrm{tanh}^2(x).$$\n",
        "\n",
        "The derivative of tanh function is plotted below.\n",
        "As the input nears 0,\n",
        "the derivative of the tanh function approaches a maximum of 1.\n",
        "And as we saw with the sigmoid function,\n",
        "as the input moves away from 0 in either direction,\n",
        "the derivative of the tanh function approaches 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASwhYKA2Q6y0",
        "colab_type": "code",
        "outputId": "3a138309-a4c0-42ca-c841-f12ac5ded959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "y.backward(torch.ones_like(x), retain_graph=True)\n",
        "xyplot(x,x.grad,\"grad of tanh\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCfIunp_Q6y2",
        "colab_type": "text"
      },
      "source": [
        "In summary, we now know how to incorporate nonlinearities\n",
        "to build expressive multilayer neural network architectures.\n",
        "As a side note, your knowledge now already\n",
        "puts you in command of the state of the art in deep learning, circa 1990.\n",
        "In fact, you have an advantage over anyone working the 1990s,\n",
        "because you can leverage powerful open-source deep learning frameworks\n",
        "to build models rapidly, using only a few lines of code.\n",
        "Previously, getting these nets training\n",
        "required researchers to code up thousands of lines of C and Fortran.\n",
        "\n",
        "## Summary\n",
        "\n",
        "* The multilayer perceptron adds one or multiple fully-connected hidden layers between the output and input layers and transforms the output of the hidden layer via an activation function.\n",
        "* Commonly-used activation functions include the ReLU function, the sigmoid function, and the tanh function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoek_AxoQiNg",
        "colab_type": "text"
      },
      "source": [
        "# Concise Implementation of Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOiaG8uQiNh",
        "colab_type": "text"
      },
      "source": [
        "Now that we learned how multilayer perceptrons (MLPs) work in theory, let’s implement them. We begin, as always, by\n",
        "importing modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmcJn4vAQiNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIdS8IiSQiNl",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC4oND-WQiNm",
        "colab_type": "text"
      },
      "source": [
        "The only difference from our softmax regression implementation is that we add two Dense (fully-connected) layers\n",
        "instead of one. The first is our hidden layer, which has 256 hidden units and uses the ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E50DJ-lBQiNm",
        "colab_type": "code",
        "outputId": "386c65ed-85ba-46a9-906a-ddeb387ed4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_inputs = 784, num_outputs = 10, num_hiddens = 256, is_training = True):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.num_hiddens = num_hiddens\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(num_inputs, num_hiddens),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Linear(num_hiddens, num_outputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.reshape((-1, self.num_inputs))\n",
        "        H1 = self.layer1(X)\n",
        "        out = self.layer2(H1)\n",
        "        return out\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)        \n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "# Create an instance of the MLP\n",
        "net = Net()\n",
        "net.apply(init_weights)\n",
        "print(net) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAAPqtba1s5Q",
        "colab_type": "text"
      },
      "source": [
        "Load the Fashion MNIST Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8KUx8Zs1ZdJ",
        "colab_type": "code",
        "outputId": "91e04856-8706-42c3-8a46-99bbf768e533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "d234f47b1b2941b8bc0fd941df65d4ab",
            "99b9eea7cf54427d9b197660a430f68d",
            "ed0497a420364e01b215df934139c6d9",
            "973a4c38bae64eb49be08ebb803f102f",
            "919227776db94af8913020b4b92b82fa",
            "bb742a1622974fb89414389699694950",
            "1d9ca606eb344acc9fd5754734c2f605",
            "a372663e245841c2917b0e11992ea5a4",
            "ccb3f0b489cb4f50a19841fc48a9df62",
            "e943dfb5fb294116a9d9b8cf872e347a",
            "1d820ad29e4948f090589603169cf4e2",
            "0a71738ef4ff49ed89a57ac7d13ec2dd",
            "9f3bcb845ad142e9b1c411a49d27f1b6",
            "74a01964c1ea4afd86d455a7495c9252",
            "25cf1cd3467940da975284e63d98676c",
            "5a9d2eaaff66477b8a85fecd49c2651d",
            "aa08981b9bb846acaab66aeca041599a",
            "6e95ae1c533544b2be826724cc59bffd",
            "d4cbf49f63cd4778959f681b6df6976e",
            "ea4cc359a8b9411fb3bb54b44b498487",
            "fdfdc92c3d7f49fa85af130561ee39b1",
            "18abfc5abc9140bb992d8fc492037eeb",
            "c819e72911ea4c779d39d5ca2b5f8ce5",
            "d2d5d58fb597419abb4a23112dd8feb7",
            "f7385ca9f4fb4bd98ec00ae3048ecbe0",
            "56b38496b0a94ebdb03a6fc62f26ef6d",
            "c215cbffd3fa45b99f201bbfb7d7bad1",
            "fdebc1050faa4e3fb573b775ba0f76b2",
            "b99c4a69a7834b71a63bcd661d750c6f",
            "98cdc065e7df415c9c8ee00b1e9e205a",
            "c61e6cad9a9349d4bce2af54588c73ac",
            "91e3cf4e54c74ccea3e454e02f37bd89"
          ]
        }
      },
      "source": [
        "# By default pytorch torchvision datasets are of type PIL.\n",
        "# Define a transform \"trans\" to change the PIL to Tensor format.\n",
        "trans = transforms.ToTensor() \n",
        "\n",
        "mnist_train = torchvision.datasets.FashionMNIST(root=\"./\", train=True, transform=trans, target_transform=None, download=True)\n",
        "mnist_test = torchvision.datasets.FashionMNIST(root=\"./\", train=False, transform=trans, target_transform=None, download=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d234f47b1b2941b8bc0fd941df65d4ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccb3f0b489cb4f50a19841fc48a9df62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa08981b9bb846acaab66aeca041599a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7385ca9f4fb4bd98ec00ae3048ecbe0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buS3TR-4AWHv",
        "colab_type": "text"
      },
      "source": [
        "Create the Data Loaders for the training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJGCjIZUAIL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "if sys.platform.startswith('win'):\n",
        "    # set 0 for windows\n",
        "    # 0 means no additional processes are needed to speed up the reading of data\n",
        "    num_workers = 0\n",
        "else:\n",
        "    num_workers = 4\n",
        "\n",
        "train_iter = DataLoader(mnist_train, batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_iter = DataLoader(mnist_test, batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NZ6Of2G59zg",
        "colab_type": "text"
      },
      "source": [
        "Set the Model Configurations: Number of epochs, learning rate (lr) and the batch-size. \n",
        "Defining the Loss (criterion)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWF0e_MTQiNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs, lr, batch_size = 10, 0.5, 256\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJe8h219QiNq",
        "colab_type": "text"
      },
      "source": [
        "Training the model follows the exact same steps as in our softmax regression implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL8Sbb0skTum",
        "colab_type": "code",
        "outputId": "347fce05-c472-48e0-d03a-5abc354b3039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "for epoch in range(num_epochs): \n",
        "  train_loss_epoch = 0.0\n",
        "  net.train()\n",
        "  for X, y in train_iter:  \n",
        "    y_hat = net(X)\n",
        "    l = criterion(y_hat, y)\n",
        "    train_loss_epoch += l\n",
        "    optimizer.zero_grad() \n",
        "    l.backward() \n",
        "    optimizer.step() \n",
        "  train_loss_epoch /= len(train_iter)\n",
        "  \n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    test_loss_epoch = 0.0\n",
        "    for X_test, y_test in test_iter:\n",
        "      b_l = criterion(net(X_test), y_test) \n",
        "      test_loss_epoch += b_l\n",
        "    test_loss_epoch /= len(test_iter)  \n",
        "  print('epoch {}, train loss {}, test loss {}'.format(epoch+1, train_loss_epoch, test_loss_epoch)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 0.7822871208190918, test loss 0.6922860145568848\n",
            "epoch 2, train loss 0.48273760080337524, test loss 0.5376869440078735\n",
            "epoch 3, train loss 0.42822298407554626, test loss 0.5391448140144348\n",
            "epoch 4, train loss 0.39352673292160034, test loss 0.44217801094055176\n",
            "epoch 5, train loss 0.3668493330478668, test loss 0.3737078309059143\n",
            "epoch 6, train loss 0.3480774760246277, test loss 0.49589842557907104\n",
            "epoch 7, train loss 0.3350205421447754, test loss 0.40118488669395447\n",
            "epoch 8, train loss 0.3238588571548462, test loss 0.36858826875686646\n",
            "epoch 9, train loss 0.30935660004615784, test loss 0.4160229563713074\n",
            "epoch 10, train loss 0.3025900423526764, test loss 0.3861441910266876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ8W4KWk7wiN",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** In the network we created above, we have used the ReLU as an activation function for the first layer. Try out different activation functions from the ones we discussed earlier in this notebook. (Keep all other parameters and hyperparameters constant). In the function below, return the value of the test *accuracy* that corresponds to the activation function you found to produce the best result. (*Hint:* You will need to recreate the network from above and then evaluate one activation function each time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_65InRKkGNL",
        "colab_type": "code",
        "outputId": "433219ee-86aa-469d-eb0b-36fe2fc95201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "    class Net1(nn.Module):\n",
        "        def __init__(self, num_inputs = 784, num_outputs = 10, num_hiddens = 256, is_training = True):\n",
        "            super(Net1, self).__init__()\n",
        "            \n",
        "            self.num_inputs = num_inputs\n",
        "            self.num_outputs = num_outputs\n",
        "            self.num_hiddens = num_hiddens\n",
        "           \n",
        "\n",
        "            self.layer1 = nn.Sequential(\n",
        "                nn.Linear(num_inputs, num_hiddens),\n",
        "                nn.ReLU()\n",
        "                )\n",
        "            self.layer2 = nn.Linear(num_hiddens, num_outputs)\n",
        "\n",
        "        def forward(self, X):\n",
        "            X = X.reshape((-1, self.num_inputs))\n",
        "            H1 = self.layer1(X)\n",
        "            #H2 = torch.tanh(H1)\n",
        "            out = self.layer2(H1)\n",
        "            return out\n",
        "\n",
        "    def init_weights(m):\n",
        "     if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)        \n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "    # Create an instance of the MLP\n",
        "   \n",
        "    net1 = Net1()\n",
        "    net1.apply(init_weights)\n",
        "    print(net1) \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net1(\n",
            "  (layer1): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (layer2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY08F__9rFMr",
        "colab_type": "code",
        "outputId": "74b3a1b2-d8ce-4987-c7c9-caa9deeae834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "    net1.apply(init_weights) # this line is to reset the weights of the network\n",
        "    num_epochs, lr, batch_size = 10, 0.5, 256\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net1.parameters(), lr = lr)\n",
        "   \n",
        "    for epoch in range(num_epochs): \n",
        "      train_loss_epoch = 0.0\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      net1.train()\n",
        "      for X, y in train_iter:  \n",
        "        y_hat = net1(X)\n",
        "        l = criterion(y_hat, y)\n",
        "        train_loss_epoch += l\n",
        "        total += y.size(0)\n",
        "        correct += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "        optimizer.zero_grad() \n",
        "        l.backward() \n",
        "        optimizer.step()\n",
        "      train_accuracy = correct/total\n",
        "      train_loss_epoch /= len(train_iter)\n",
        "    \n",
        "      net1.eval()\n",
        "      with torch.no_grad():\n",
        "        test_loss_epoch = 0.0\n",
        "        total_test = 0\n",
        "        correct_test = 0\n",
        "        for X_test, y_test in test_iter:\n",
        "          y_test_hat = net1(X_test)\n",
        "          b_l = criterion(y_test_hat, y_test) \n",
        "          test_loss_epoch += b_l\n",
        "          total_test += y_test.size(0)\n",
        "          correct_test += (y_test_hat.argmax(dim=1) == y_test).sum().item() \n",
        "        test_loss_epoch /= len(test_iter)  \n",
        "        test_accuracy = correct_test/total_test\n",
        "      print('epoch {}, train loss {}, train aacuracy{}, test loss {}, test accuracy{}'.format(epoch+1, train_loss_epoch,train_accuracy ,test_loss_epoch,test_accuracy)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 0.8138970732688904, train aacuracy0.6993333333333334, test loss 0.5163170099258423, test accuracy0.8062\n",
            "epoch 2, train loss 0.49108216166496277, train aacuracy0.8182, test loss 0.45148783922195435, test accuracy0.8314\n",
            "epoch 3, train loss 0.4282894730567932, train aacuracy0.84195, test loss 0.4926125109195709, test accuracy0.8059\n",
            "epoch 4, train loss 0.3933418393135071, train aacuracy0.8568833333333333, test loss 0.47005948424339294, test accuracy0.8338\n",
            "epoch 5, train loss 0.36898308992385864, train aacuracy0.86295, test loss 0.41244983673095703, test accuracy0.85\n",
            "epoch 6, train loss 0.3492032289505005, train aacuracy0.8711666666666666, test loss 0.39769840240478516, test accuracy0.8488\n",
            "epoch 7, train loss 0.33800187706947327, train aacuracy0.8744833333333333, test loss 0.3902105689048767, test accuracy0.8589\n",
            "epoch 8, train loss 0.3260251581668854, train aacuracy0.8775833333333334, test loss 0.36910778284072876, test accuracy0.8668\n",
            "epoch 9, train loss 0.3176521062850952, train aacuracy0.8812666666666666, test loss 0.3775237798690796, test accuracy0.853\n",
            "epoch 10, train loss 0.3035198152065277, train aacuracy0.8882666666666666, test loss 0.4254686236381531, test accuracy0.8436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzzBoFKFqlDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_accuracy_from_activation_function(train_iter, test_iter):\n",
        "  test_accuracy = 0.0\n",
        "  ## write your code here\n",
        "  class Net1(nn.Module):\n",
        "        def __init__(self, num_inputs = 784, num_outputs = 10, num_hiddens = 256, is_training = True):\n",
        "            super(Net1, self).__init__()\n",
        "            \n",
        "            self.num_inputs = num_inputs\n",
        "            self.num_outputs = num_outputs\n",
        "            self.num_hiddens = num_hiddens\n",
        "           \n",
        "\n",
        "            self.layer1 = nn.Sequential(\n",
        "                nn.Linear(num_inputs, num_hiddens),\n",
        "                nn.PReLU(256)\n",
        "                )\n",
        "            self.layer2 = nn.Linear(num_hiddens, num_outputs)\n",
        "\n",
        "        def forward(self, X):\n",
        "            X = X.reshape((-1, self.num_inputs))\n",
        "            H1 = self.layer1(X)\n",
        "            #H2 = torch.tanh(H1)\n",
        "            out = self.layer2(H1)\n",
        "            return out\n",
        "\n",
        "  def init_weights(m):\n",
        "     if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)        \n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "    # Create an instance of the MLP\n",
        "   \n",
        "  net1 = Net1()\n",
        "  net1.apply(init_weights)\n",
        "  net1.apply(init_weights) # this line is to reset the weights of the network\n",
        "  num_epochs, lr, batch_size = 10, 0.5, 256\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(net1.parameters(), lr = lr)\n",
        "   \n",
        "  for epoch in range(num_epochs): \n",
        "      train_loss_epoch = 0.0\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      net1.train()\n",
        "      for X, y in train_iter:  \n",
        "        y_hat = net1(X)\n",
        "        l = criterion(y_hat, y)\n",
        "        train_loss_epoch += l\n",
        "        total += y.size(0)\n",
        "        correct += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "        optimizer.zero_grad() \n",
        "        l.backward() \n",
        "        optimizer.step()\n",
        "      train_accuracy = correct/total\n",
        "      train_loss_epoch /= len(train_iter)\n",
        "    \n",
        "      net1.eval()\n",
        "      with torch.no_grad():\n",
        "        test_loss_epoch = 0.0\n",
        "        total_test = 0\n",
        "        correct_test = 0\n",
        "        for X_test, y_test in test_iter:\n",
        "          y_test_hat = net1(X_test)\n",
        "          b_l = criterion(y_test_hat, y_test) \n",
        "          test_loss_epoch += b_l\n",
        "          total_test += y_test.size(0)\n",
        "          correct_test += (y_test_hat.argmax(dim=1) == y_test).sum().item() \n",
        "        test_loss_epoch /= len(test_iter)  \n",
        "        test_accuracy = correct_test/total_test\n",
        "      #print('epoch {}, train loss {}, train aacuracy{}, test loss {}, test accuracy{}'.format(epoch+1, train_loss_epoch,train_accuracy ,test_loss_epoch,test_accuracy)) \n",
        " \n",
        "  \n",
        "  ## ReLu : 0.8436\n",
        "  #test_accuracy = 0.8631   \n",
        "  ## PreLu : 0.8631   \n",
        "  ## sigmoid: 0.8502\n",
        "  ## tanh: 0.8544\n",
        "  ## end of code\n",
        "  return test_accuracy\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwwbQxrZ7kCv",
        "colab_type": "code",
        "outputId": "2b9c1aeb-d9b2-4f01-8403-12cbb6f5fbaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " best_accuracy_from_activation_function(train_iter, test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jE8o5-ssq8S",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection, Underfitting and Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz_3I3ihshGz",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection\n",
        "\n",
        "In machine learning, we usually select our final model\n",
        "after evaluating several candidate models.\n",
        "This process is called model selection.\n",
        "Sometimes the models subject to comparison\n",
        "are fundamentally different in nature\n",
        "(say, decision trees vs linear models).\n",
        "At other times, we are comparing\n",
        "members of the same class of models\n",
        "that have been trained with different hyperparameter settings.\n",
        "\n",
        "With multilayer perceptrons for example,\n",
        "we may wish to compare models with\n",
        "different numbers of hidden layers,\n",
        "different numbers of hidden units,\n",
        "and various choices of the activation functions\n",
        "applied to each hidden layer.\n",
        "In order to determine the best among our candidate models,\n",
        "we will typically employ a validation set.\n",
        "\n",
        "\n",
        "### Validation Dataset\n",
        "\n",
        "In principle we should not touch our test set\n",
        "until after we have chosen all our hyper-parameters.\n",
        "Were we to use the test data in the model selection process,\n",
        "there is a risk that we might overfit the test data.\n",
        "Then we would be in serious trouble.\n",
        "If we overfit our training data,\n",
        "there is always the evaluation on test data to keep us honest.\n",
        "But if we overfit the test data, how would we ever know?\n",
        "\n",
        "\n",
        "Thus, we should never rely on the test data for model selection.\n",
        "And yet we cannot rely solely on the training data\n",
        "for model selection either because\n",
        "we cannot estimate the generalization error\n",
        "on the very data that we use to train the model.\n",
        "\n",
        "The common practice to address this problem\n",
        "is to split our data three ways,\n",
        "incorporating a *validation set*\n",
        "in addition to the training and test sets.\n",
        "\n",
        "\n",
        "In practical applications, the picture gets muddier.\n",
        "While ideally we would only touch the test data once,\n",
        "to assess the very best model or to compare\n",
        "a small number of models to each other,\n",
        "real-world test data is seldom discarded after just one use.\n",
        "We can seldom afford a new test set for each round of experiments.\n",
        "\n",
        "The result is a murky practice where the boundaries\n",
        "between validation and test data are worryingly ambiguous.\n",
        "Unless explicitly stated otherwise, in the experiments in this book\n",
        "we are really working with what should rightly be called\n",
        "training data and validation data, with no true test sets.\n",
        "Therefore, the accuracy reported in each experiment\n",
        "is really the validation accuracy and not a true test set accuracy.\n",
        "The good news is that we do not need too much data in the validation set.\n",
        "The uncertainty in our estimates can be shown\n",
        "to be of the order of $\\mathcal{O}(n^{-\\frac{1}{2}})$.\n",
        "\n",
        "\n",
        "### $K$-Fold Cross-Validation\n",
        "\n",
        "When training data is scarce,\n",
        "we might not even be able to afford to hold out\n",
        "enough data to constitute a proper validation set.\n",
        "One popular solution to this problem is to employ\n",
        "$K$*-fold cross-validation*.\n",
        "Here, the original training data is split into $K$ non-overlapping subsets.\n",
        "Then model training and validation are executed $K$ times,\n",
        "each time training on $K-1$ subsets and validating\n",
        "on a different subset (the one not used for training in that round).\n",
        "Finally, the training and validation error rates are estimated\n",
        "by averaging over the results from the $K$ experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yYdUa3W9kI2",
        "colab_type": "text"
      },
      "source": [
        "**Exercise:** Implement a 5-fold validation scheme using the training data set from FashionMNIST. The function below should return the *average* accuracy over all 5 folds. Note: Use the same network, parameters, hyperparameters, and data from above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc3TAzce9zKl",
        "colab_type": "code",
        "outputId": "019c1bea-81b1-48ad-9d4e-ff033f72ff97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def five_fold_validation(train_iter, test_iter):\n",
        "  from sklearn.model_selection import KFold\n",
        "  batch_size = 256\n",
        "  if sys.platform.startswith('win'):\n",
        "    # set 0 for windows\n",
        "    # 0 means no additional processes are needed to speed up the reading of data\n",
        "    num_workers = 0\n",
        "  else:\n",
        "    num_workers = 4\n",
        "  avg_accuracy = 0.0\n",
        "  K = 5   # number of folds\n",
        "  \n",
        "  ## Write your code here\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(root=\"./\", train=True, transform=trans, target_transform=None, download=True)\n",
        "  #mnist_test = torchvision.datasets.FashionMNIST(root=\"./\", train=False, transform=trans, target_transform=None, download=True)\n",
        "  #train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
        "  class Net(nn.Module):\n",
        "    def __init__(self, num_inputs = 784, num_outputs = 10, num_hiddens = 256, is_training = True):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.num_hiddens = num_hiddens\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(num_inputs, num_hiddens),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Linear(num_hiddens, num_outputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X.reshape((-1, self.num_inputs))\n",
        "        H1 = self.layer1(X)\n",
        "        out = self.layer2(H1)\n",
        "        return out\n",
        "\n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.normal_(m.weight, std=0.01)        \n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "  # Create an instance of the MLP\n",
        "  net = Net()\n",
        "  net.apply(init_weights)\n",
        "  \n",
        "  num_epochs, lr, batch_size = 10, 0.5, 256\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "  kfold = KFold(K,True,1)\n",
        "  i =1\n",
        "  for train, test in kfold.split(mnist_train):\n",
        "    net.apply(init_weights) # this line is to reset the weights of the network\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr = lr)\n",
        "    #testdata = torch.index_select(mnist_train,0, train_idx, testdata)\n",
        "    train_data = torch.utils.data.Subset(mnist_train, train)\n",
        "    test_data =torch.utils.data.Subset(mnist_train, test)\n",
        "    train_iter = DataLoader(mnist_train, batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_iter = DataLoader(mnist_test, batch_size, shuffle=False, num_workers=num_workers)\n",
        "    #print('train: {}, test: {}'.format(train, test))\n",
        "    #print(len(train_iter))\n",
        "    \n",
        "    for epoch in range(num_epochs): \n",
        "      train_loss_epoch = 0.0\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      net.train()\n",
        "      for X, y in train_iter:  \n",
        "        y_hat = net(X)        \n",
        "        l = criterion(y_hat, y)\n",
        "        train_loss_epoch += l\n",
        "        total += y.size(0)\n",
        "        correct += (y_hat.argmax(dim=1) == y).sum().item()\n",
        "        optimizer.zero_grad() \n",
        "        l.backward() \n",
        "        optimizer.step()\n",
        "      train_accuracy = correct/total\n",
        "      train_loss_epoch /= len(train_iter)\n",
        "    \n",
        "      net.eval()\n",
        "      with torch.no_grad():\n",
        "        test_loss_epoch = 0.0\n",
        "        for X_test, y_test in test_iter:\n",
        "          y_test_hat = net(X_test)\n",
        "          b_l = criterion(y_test_hat, y_test) \n",
        "          test_loss_epoch += b_l\n",
        "          total += y_test.size(0)\n",
        "          correct += (y_test_hat.argmax(dim=1) == y_test).sum().item() \n",
        "        test_loss_epoch /= len(test_iter)  \n",
        "        test_accuracy = correct/total\n",
        "      #print('epoch {}, train loss {}, train aacuracy{}, test loss {}, test accuracy{}'.format(epoch+1, train_loss_epoch,train_accuracy ,test_loss_epoch,test_accuracy)) \n",
        "    avg_accuracy += test_accuracy\n",
        "    #print(\"split:{},Accuracy:{} \".format(i,test_accuracy))\n",
        "    i=i+1;\n",
        "  avg_accuracy /= K\n",
        "  ## end of function\n",
        "  return avg_accuracy\n",
        "\n",
        "\n",
        "#five_fold_validation(train_iter, test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H67vehrf9fNs",
        "colab_type": "text"
      },
      "source": [
        "# Underfitting or Overfitting?\n",
        "When we compare the training and validation errors, we want to be mindful of two common situations: First, we want\n",
        "to watch out for cases when our training error and validation error are both substantial but there is a little gap between\n",
        "them. If the model is unable to reduce the training error, that could mean that our model is too simple (i.e., insufficiently\n",
        "expressive) to capture the pattern that we are trying to model. Moreover, since the generalization gap between our training\n",
        "and validation errors is small, we have reason to believe that we could get away with a more complex model. This\n",
        "phenomenon is known as underfitting.\n",
        "\n",
        "On the other hand, as we discussed above, we want to watch out for the cases when our training error is significantly lower\n",
        "than our validation error, indicating severe overfitting. Note that overfitting is not always a bad thing. With deep learning\n",
        "especially, it’s well known that the best predictive models often perform far better on training data than on holdout data.\n",
        "\n",
        "Ultimately, we usually care more about the validation error than about the gap between the training and validation errors.\n",
        "Whether we overfit or underfit can depend both on the complexity of our model and the size of the available training\n",
        "datasets, two topics that we discuss below.\n",
        "\n",
        "## Model Complexity \n",
        "\n",
        "To illustrate some classical intuition about overfitting and model complexity, we given an example using polynomials.\n",
        "Given training data consisting of a single feature x and a corresponding real-valued label y, we try to find the polynomial\n",
        "of degree d\n",
        "\n",
        "$$y=\\sum_{i=0}^d\\ W^ix^i$$\n",
        "\n",
        "to estimate the labels y. This is just a linear regression problem where our features are given by the powers of x, the wi\n",
        "given the model’s weights, and the bias is given by w0 since x\n",
        "0 = 1 for all x. Since this is just a linear regression problem,\n",
        "we can use the squared error as our loss function.\n",
        "A higher-order polynomial function is more complex than a lower order polynomial function, since the higher-order polynomial has more parameters and the model function’s selection range is wider. Fixing the training data set, higher-order\n",
        "polynomial functions should always achieve lower (at worst, equal) training error relative to lower degree polynomials.\n",
        "In fact, whenever the data points each have a distinct value of x, a polynomial function with degree equal to the number\n",
        "of data points can fit the training set perfectly. We visualize the relationship between polynomial degree and under- vs\n",
        "over-fitting below.\n",
        "\n",
        "## Data Set Size\n",
        "\n",
        "The other big consideration to bear in mind is the dataset size. Fixing our model, the fewer samples we have in the\n",
        "training dataset, the more likely (and more severely) we are to encounter overfitting. As we increase the amount of\n",
        "training data, the generalization error typically decreases. Moreover, in general, more data never hurts. For a fixed task\n",
        "and data distribution, there is typically a relationship between model complexity and dataset size. Given more data, we\n",
        "might profitably attempt to fit a more complex model. Absent sufficient data, simpler models may be difficult to beat. For\n",
        "many tasks, deep learning only outperforms linear models when many thousands of training examples are available. In part, the current success of deep learning owes to the current abundance of massive datasets due to internet companies,\n",
        "cheap storage, connected devices, and the broad digitization of the economy.\n",
        "\n",
        "## Polynomial Regression\n",
        "We can now explore these concepts interactively by fitting polynomials to data. To get started we’ll import our usual\n",
        "packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "973_Ufhz9fNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIes1em49fNw",
        "colab_type": "text"
      },
      "source": [
        "## Generating Data Sets\n",
        "\n",
        "First we need data. Given x, we will use the following cubic polynomial to generate the labels on training and test data:\n",
        "\n",
        "$$y=5+1.2x-3.4\\frac{x^2}{2!}+5.6\\frac{x^3}{3!}+ E where E-N(0,0.1)$$\n",
        "\n",
        "The noise term ϵ obeys a normal distribution with a mean of 0 and a standard deviation of 0.1. We’ll synthesize 100\n",
        "samples each for the training set and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFY-xoDc9fNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_degree=20\n",
        "n_train,n_test=100,100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fai0nHcw9fNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poly_features=torch.zeros(20,200)\n",
        "true_w=torch.zeros(max_degree)\n",
        "true_w[0:4] = torch.tensor([5, 1.2, -3.4, 5.6])\n",
        "features = torch.randn(size=(n_train + n_test, 1))\n",
        "x_list=torch.arange(max_degree)\n",
        "x_list.float()\n",
        "features=features.reshape(1,-1)\n",
        "\n",
        "for i in range(1,max_degree):\n",
        "    \n",
        "    poly_features[i] = torch.pow(features,i)\n",
        "    \n",
        "print(features[:,4])\n",
        "print(poly_features[:,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTPi2hwn9fN1",
        "colab_type": "text"
      },
      "source": [
        "For optimization, we typically want to avoid very large values of gradients, losses, etc. This is why the monomials stored\n",
        "in poly_features are rescaled from x\n",
        "\n",
        "It allows us to avoid very large values for large exponents i. Factorials\n",
        "are implemented in Gluon using the Gamma function, where n! = Γ(n + b 1).\n",
        "Take a look at the first 2 samples from the generated data set. The value 1 is technically a feature, namely the constant\n",
        "feature corresponding to the bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNjqZOGw9fN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.special import factorial\n",
        "ok=torch.arange(1,(max_degree) + 1).reshape((1, -1))\n",
        "\n",
        "dr=factorial(ok)\n",
        "\n",
        "dr2=torch.from_numpy(dr)\n",
        "\n",
        "poly_features = poly_features.double() /dr2.t()\n",
        "\n",
        "labels = torch.matmul(true_w.double(),poly_features)\n",
        "\n",
        "poly_features = poly_features.type(torch.FloatTensor)\n",
        "\n",
        "labels = labels.type(torch.FloatTensor)\n",
        "\n",
        "labels += torch.randn(200)*0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPxGr6ek9fN4",
        "colab_type": "text"
      },
      "source": [
        "### Defining, Training and Testing Model\n",
        "We first define the plotting functionsemilogy, where the y axis makes use of the logarithmic scale\n",
        "\n",
        "Since we will be attempting to fit the generated dataset using models of varying complexity, we insert the model definition\n",
        "into the fit_and_plot function. The training and testing steps involved in polynomial function fitting are similar to\n",
        "those previously described in softmax regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw1ZyFfu9fN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None, legend=None, figsize=(3.5, 2.5)):    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.semilogy(x_vals, y_vals)\n",
        "    if x2_vals and y2_vals:\n",
        "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
        "        plt.legend(legend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i-GZMV29fN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_and_plot(train_features,train_labels,test_features,test_labels,no_inputs):\n",
        "    class LinearRegressionModel(torch.nn.Module): \n",
        "        def __init__(self): \n",
        "            super(LinearRegressionModel, self).__init__() \n",
        "            self.linear = torch.nn.Linear(no_inputs, 1)  \n",
        "  \n",
        "        def forward(self, x): \n",
        "            y_pred = self.linear(x) \n",
        "            return y_pred \n",
        "    \n",
        "    model = LinearRegressionModel() \n",
        "    criterion = torch.nn.MSELoss(reduction='sum') \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "    train_ls,test_ls=[],[]   \n",
        "    train_labels=train_labels.reshape(-1,1)\n",
        "    train_ds=TensorDataset(train_features,train_labels)\n",
        "    batch_size=10\n",
        "    train_dl=DataLoader(train_ds,batch_size,shuffle=True)    \n",
        "    test_labels=test_labels.reshape(-1,1)\n",
        "    for ep in range(100):\n",
        "        for xb,yb in train_dl:         \n",
        "            pred_y = model(xb)     \n",
        "            loss = criterion(pred_y, yb)             \n",
        "            optimizer.zero_grad() \n",
        "            loss.backward() \n",
        "            optimizer.step()\n",
        "          \n",
        "        predytr=model(train_features)\n",
        "        train_ls.append((criterion(predytr,train_labels)).mean())\n",
        "        predyts=model(test_features)\n",
        "        test_ls.append((criterion(predyts,test_labels)).mean())    \n",
        "    \n",
        "    print('final epoch:train loss',train_ls[-1],'test Loss',test_ls[-1])\n",
        "    semilogy(range(1,ep+2), train_ls,'epoch','loss',range(1,ep+2),test_ls,['train','test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kja7I86v9fN9",
        "colab_type": "text"
      },
      "source": [
        "### Third-order Polynomial Function Fitting (Normal)\n",
        "\n",
        "We will begin by first using a third-order polynomial function with the same order as the data generation function. The\n",
        "results show that this model’s training error rate when using the testing data set is low. The trained model parameters are\n",
        "also close to the true values w = [5, 1.2, −3.4, 5.6].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7OcI-OQ9fN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poly_features_t=poly_features.t()\n",
        "fit_and_plot(train_features=poly_features_t[:100,0:4],train_labels=labels[:100],test_features=poly_features_t[100:,0:4],test_labels=labels[100:],no_inputs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKaBc4WJ9fOA",
        "colab_type": "text"
      },
      "source": [
        "## Linear Function Fitting\n",
        "Let’s take another look at linear function fitting. After the decline in the early epoch, it becomes difficult to further\n",
        "decrease this model’s training error rate. After the last epoch iteration has been completed, the training error rate is\n",
        "still high. When used to fit non-linear patterns (like the third-order polynomial function here) linear models are liable to\n",
        "underfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "na-5Vv3-9fOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_and_plot(train_features=poly_features_t[:100,0:3],train_labels=labels[:100],test_features=poly_features_t[100:,0:3],test_labels=labels[100:],no_inputs=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTyiIuGa9fOC",
        "colab_type": "text"
      },
      "source": [
        "## Insufficient Training(Overfitting)\n",
        "Now let’s try to train the model using a polynomial of too high degree. Here, there is insufficient data to learn that the\n",
        "higher-degree coefficients should have values close to zero. As a result, our overly-complex model is far too susceptible\n",
        "to being influenced by noise in the training data. Of course, our training error will now be low (even lower than if we had\n",
        "the right model!) but our test error will be high.\n",
        "Try out different model complexities (n_degree) and training set sizes (n_subset) to gain some intuition of what is\n",
        "happening.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nElQOGu9fOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit_and_plot(train_features=poly_features_t[1:100,0:20],train_labels=labels[1:100],test_features=poly_features_t[100:,0:20],test_labels=labels[100:],no_inputs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3acPbUW3FlVz",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "*   Since the generalization error rate cannot be estimated based on the training error rate, simply minimizing the training error rate will not necessarily mean a reduction in the generalization error rate. Machine learning models need to be careful to safeguard against overfitting such as to minimize the generalization error.\n",
        "*    A validation set can be used for model selection (provided that it is not used too liberally).\n",
        "*    Underfitting means that the model is not able to reduce the training error rate, while overfitting is a result of the model training error rate being much lower than the testing dataset rate.\n",
        "*    We should choose an appropriately complex model and avoid using insufficient training samples.\n"
      ]
    }
  ]
}